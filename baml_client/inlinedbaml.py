###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "bio.baml": "// This is a BAML config file, which extends the Jinja2 templating language to write LLM functions.\nclass Biography {\n  name string @alias(#\"first_name\"#)\n  surname string @alias(#\"last_name\"#)\n  birth_place string \n  biography string \n}\n\nfunction GenerateBiographies(person_count: int) -> Biography[] {\n  // see clients.baml\n  client GPT35\n\n  // The prompt uses Jinja syntax. Change the models or this text and watch the prompt preview change!\n  prompt #\"\n    Generate {{person_count}} sample biographies in the following format:\n\n    {# special macro to print the output instructions. #}\n    {{ ctx.output_format }}\n\n    JSON:\n  \"#\n}\n\ntest Test1 {\n  functions [GenerateBiographies]\n  args {\n    person_count 3\n  }\n}",
    "clients.baml": "client<llm> GPT4 {\n  provider openai\n  options {\n    model \"gpt-4\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> Claude {\n  provider anthropic\n  options {\n    model \"claude-3-opus-20240229\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> FastAnthropic {\n  provider anthropic\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> GPT35 {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n\nclient<llm> Fast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [FastAnthropic, FastOpenAI]\n  }\n}\n\nclient<llm> Openai {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [GPT4, FastOpenAI]\n  }\n}",
    "generators.baml": "\n// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\"\n    output_type \"python/pydantic\"\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n}\n        ",
}

def get_baml_files():
    return file_map